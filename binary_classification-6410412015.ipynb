{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"StudentName : คุณานนต์ กลิ่นจันทร์หอม Rank 30\n\nID : 6410412015","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-12T10:39:01.291427Z","iopub.execute_input":"2022-06-12T10:39:01.292037Z","iopub.status.idle":"2022-06-12T10:39:01.301121Z","shell.execute_reply.started":"2022-06-12T10:39:01.292002Z","shell.execute_reply":"2022-06-12T10:39:01.30022Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Import Data & Python Packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\n#import model libraries\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n\n#import model optimize funcition\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.pipeline import Pipeline\n\n#import model optimize funcition\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#visualisation the data\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport warnings\nwarnings.simplefilter(action='ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:51:19.340893Z","iopub.execute_input":"2022-06-12T12:51:19.341359Z","iopub.status.idle":"2022-06-12T12:51:21.181817Z","shell.execute_reply.started":"2022-06-12T12:51:19.341275Z","shell.execute_reply":"2022-06-12T12:51:21.180681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/dads6003-in-class-competition/train.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:51:21.183049Z","iopub.execute_input":"2022-06-12T12:51:21.183272Z","iopub.status.idle":"2022-06-12T12:51:21.279227Z","shell.execute_reply.started":"2022-06-12T12:51:21.183237Z","shell.execute_reply":"2022-06-12T12:51:21.278435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/dads6003-in-class-competition/test.csv')\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:51:44.030952Z","iopub.execute_input":"2022-06-12T12:51:44.031409Z","iopub.status.idle":"2022-06-12T12:51:44.078246Z","shell.execute_reply.started":"2022-06-12T12:51:44.031361Z","shell.execute_reply":"2022-06-12T12:51:44.077385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Data Cleansing\n","metadata":{}},{"cell_type":"markdown","source":"การทำความสะอาดข้อมูลเป็นสิ่งสำคัญ การทำความสะอาดข้อมูล หรือการทำข้อมูลให้สมบูรณ์ เป็นกระบวนการตรวจสอบและการแก้ไข รายการข้อมูลที่ไม่ถูกต้องออกไปจากชุดข้อมูล ตารางหรือฐานข้อมูล ซึ่งเป็นหลักสำคัญของฐานข้อมูล เพราะหมายถึงความไม่สมบูรณ์ ความไม่ถูกต้อง ความไม่สัมพันธ์กับข้อมูลอื่นๆ เป็นต้น จึงต้องมีการแทนที่ การปรับปรุง หรือการลบข้อมูลที่ไม่ถูกต้องเหล่านี้ออกไป เพื่อให้ข้อมูลมีคุณภาพ\n1. การจัดการข้อมูลที่หาย(missing values)\n2. การจัดการ outlier\n3. การ Scaler ข้อมูลให้อยู่ใน scale เดียวกัน\n4. การจัดการ feature ที่ไม่มีผลต่อการ predict\n\n","metadata":{}},{"cell_type":"code","source":"dataset = pd.concat(objs=[df_train,df_test], axis=0).reset_index(drop=True)\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:51:46.501101Z","iopub.execute_input":"2022-06-12T12:51:46.501403Z","iopub.status.idle":"2022-06-12T12:51:46.53665Z","shell.execute_reply.started":"2022-06-12T12:51:46.50137Z","shell.execute_reply":"2022-06-12T12:51:46.536052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:51:51.901101Z","iopub.execute_input":"2022-06-12T12:51:51.901636Z","iopub.status.idle":"2022-06-12T12:51:51.980706Z","shell.execute_reply.started":"2022-06-12T12:51:51.901599Z","shell.execute_reply":"2022-06-12T12:51:51.979918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"จากข้อมูลทางสถิติเบื่องต้นในแต่ละ feature ค่อนข้างแตกต่างกัน อยู่ใน range ที่แตกต่างกันมาก การ train model จะไม่สามารถ ถึงจุด optimize ได้ แต่ในที่นี้เราจะมาทำการ EDA แต่และจัดการข้อมูลให้ดีพร้อมในการเทรนโมเดลต่อไป","metadata":{}},{"cell_type":"code","source":"dataset.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:51:54.965804Z","iopub.execute_input":"2022-06-12T12:51:54.966959Z","iopub.status.idle":"2022-06-12T12:51:54.985654Z","shell.execute_reply.started":"2022-06-12T12:51:54.9669Z","shell.execute_reply":"2022-06-12T12:51:54.984798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ดูข้อมูล missing values ที่หายไปในแต่ละ feature ","metadata":{}},{"cell_type":"code","source":"dataset.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:51:57.251183Z","iopub.execute_input":"2022-06-12T12:51:57.251464Z","iopub.status.idle":"2022-06-12T12:51:57.260281Z","shell.execute_reply.started":"2022-06-12T12:51:57.251432Z","shell.execute_reply":"2022-06-12T12:51:57.259154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape,df_train.shape,df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:51:59.81081Z","iopub.execute_input":"2022-06-12T12:51:59.811605Z","iopub.status.idle":"2022-06-12T12:51:59.817116Z","shell.execute_reply.started":"2022-06-12T12:51:59.811561Z","shell.execute_reply":"2022-06-12T12:51:59.816486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.fillna(0)\ndf_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:52:01.815804Z","iopub.execute_input":"2022-06-12T12:52:01.816324Z","iopub.status.idle":"2022-06-12T12:52:01.826128Z","shell.execute_reply.started":"2022-06-12T12:52:01.816288Z","shell.execute_reply":"2022-06-12T12:52:01.825162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"จัดการ missing values ด้วยการให้ค่านั้นเป็น 0 หรือ ที่ต้องการแต่ในที่นี้ให้เป็น 0\n","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:52:04.131028Z","iopub.execute_input":"2022-06-12T12:52:04.131359Z","iopub.status.idle":"2022-06-12T12:52:04.154472Z","shell.execute_reply.started":"2022-06-12T12:52:04.131318Z","shell.execute_reply":"2022-06-12T12:52:04.153517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ปรับขนาดแต่ละคุณลักษณะด้วยค่าสัมบูรณ์สูงสุด(MaxAbsScaler)**\n\n    ตัวประมาณนี้จะปรับขนาดและแปลคุณลักษณะแต่ละอย่างแยกกัน เพื่อให้ค่าสัมบูรณ์สูงสุดของคุณลักษณะแต่ละรายการในชุดการฝึกจะเป็น 1.0 ไม่เลื่อน/จัดศูนย์กลางข้อมูล จึงไม่ทำลายความกระจัดกระจายใดๆ โดยทำทั้ง Train , Test data set","metadata":{}},{"cell_type":"code","source":"df_train_norm = df_train.copy()\n#normalization dataset\nfor column in df_train_norm.columns:\n    df_train_norm[column] = df_train_norm[column]  / df_train_norm[column].abs().max()\n      \n'''\nfor col in df_train.columns:\n    df_train[col] = normalize(df_train,norm =)\n'''\ndf_train_norm.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:52:06.850875Z","iopub.execute_input":"2022-06-12T12:52:06.851515Z","iopub.status.idle":"2022-06-12T12:52:06.889556Z","shell.execute_reply.started":"2022-06-12T12:52:06.851472Z","shell.execute_reply":"2022-06-12T12:52:06.888731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_norm = df_test.copy()\n#normalization dataset\nfor column in df_test_norm.columns:\n    df_test_norm[column] = df_test_norm[column]  / df_test_norm[column].abs().max()\n      \n'''\nfor col in df_train.columns:\n    df_train[col] = normalize(df_train,norm =)\n'''\ndf_test_norm.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:52:09.350704Z","iopub.execute_input":"2022-06-12T12:52:09.351487Z","iopub.status.idle":"2022-06-12T12:52:09.385538Z","shell.execute_reply.started":"2022-06-12T12:52:09.351447Z","shell.execute_reply":"2022-06-12T12:52:09.384949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:52:12.006447Z","iopub.execute_input":"2022-06-12T12:52:12.007164Z","iopub.status.idle":"2022-06-12T12:52:12.013306Z","shell.execute_reply.started":"2022-06-12T12:52:12.007122Z","shell.execute_reply":"2022-06-12T12:52:12.01266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**การจัดการ outlier**\n\n    Outlier คือ data points ที่มีค่าสูงหรือต่ำกว่า data points ส่วนใหญ่ในชุดข้อมูลหนึ่งๆอย่างมาก เช่น ส่วนสูง 210 cm คือค่า outlier สำหรับคนไทย เพราะเราแทบไม่เคยเห็นคนไทยสูงเกิน 2 เมตรเลย เป็นต้น อ้างอิงสถิติจากเว็บไซต์ sizethailand ส่วนสูงเฉลี่ยชายและหญิงชาวไทย อายุ 16-25 ปี อยู่ที่ 171 cm และ 159 cm ตามลำดับ\n    \n    โดยในการจัดการข้อมูลชุดนี้จัดโดยวิธ๊ IQR\n    ซึ่ง Outlier จะอยู่ที่ด้านปลายทั้งสองของ Distribution ใช้ค่า factor k โดยทั่วไปจะกำหนดไว้ที่ 1.5 ถึง 3 เท่าของค่า IQR โปรดที่ดูที่รูปด้านล่างประกอบ ที่ 1.5IQR คือพื้นที่ที่ยังคงเป็น Normally อยู่ทั้งนี้ \n    \n    Lower Anomaly = Q1 - 1.5 x IQR\n    Upper Anomaly = Q3 + 1.5 x IQR","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(figsize = (8,8))\nsns.boxplot(data=df_train_norm,x='x1',color='orange')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:52:37.626825Z","iopub.execute_input":"2022-06-12T12:52:37.627681Z","iopub.status.idle":"2022-06-12T12:52:37.84045Z","shell.execute_reply.started":"2022-06-12T12:52:37.627621Z","shell.execute_reply":"2022-06-12T12:52:37.839481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"boxplot แสดงให้เห็นข้อมูลที่อยู่นอกช่วง","metadata":{}},{"cell_type":"code","source":"#IQR range\nQ1 = df_train_norm.quantile(0.25)\nQ3 = df_train_norm.quantile(0.75)\nIQR = Q3 - Q1\n\noutlier_step = IQR*1.5\n\n#print(df_train_norm < (Q1 - 1.5 * IQR)) |(df_train_norm > (Q3 + 1.5 * IQR))        \ndf_out = df_train_norm[~((df_train_norm < (Q1 - outlier_step)) |(df_train_norm > (Q3 + outlier_step))).any(axis=1)].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:52:46.537397Z","iopub.execute_input":"2022-06-12T12:52:46.538001Z","iopub.status.idle":"2022-06-12T12:52:46.560631Z","shell.execute_reply.started":"2022-06-12T12:52:46.53796Z","shell.execute_reply":"2022-06-12T12:52:46.559725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_out.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:53:04.941283Z","iopub.execute_input":"2022-06-12T12:53:04.941561Z","iopub.status.idle":"2022-06-12T12:53:04.947901Z","shell.execute_reply.started":"2022-06-12T12:53:04.941533Z","shell.execute_reply":"2022-06-12T12:53:04.947006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"หลังจากจัดการ outlier ข้อมูลหายไปจำนวนมาก ซึ่งอาจมีผลต่อการเทรนโมเดล จาก 7500 rows เหลือ 5179 rows ซึ่งหายไป 2000 กว่าๆ แถว ","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(figsize = (8,8))\nsns.boxplot(data=df_out,x='x1',color='orange')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:53:07.175658Z","iopub.execute_input":"2022-06-12T12:53:07.175975Z","iopub.status.idle":"2022-06-12T12:53:07.350684Z","shell.execute_reply.started":"2022-06-12T12:53:07.175946Z","shell.execute_reply":"2022-06-12T12:53:07.34973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6, 8))\nsns.countplot(x=\"y\", data=df_out, color=\"c\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:53:09.520893Z","iopub.execute_input":"2022-06-12T12:53:09.521157Z","iopub.status.idle":"2022-06-12T12:53:09.695801Z","shell.execute_reply.started":"2022-06-12T12:53:09.521129Z","shell.execute_reply":"2022-06-12T12:53:09.694757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_out['y'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:53:12.501449Z","iopub.execute_input":"2022-06-12T12:53:12.501773Z","iopub.status.idle":"2022-06-12T12:53:12.511457Z","shell.execute_reply.started":"2022-06-12T12:53:12.501736Z","shell.execute_reply":"2022-06-12T12:53:12.510612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"จากการดู ข้อมูลเบื้องต้นพบว่าข้อมูลหายไปเยอะ และเกิด imbalance data ขึ้น ซึ่ง label ที่เป็น 0 มี 4014 และ ที่เป็น 1 มี 1165 ซึ่งข้อมูลไม่สมมาตรกัน","metadata":{}},{"cell_type":"code","source":"df_out['y'].value_counts().plot(kind = 'pie',figsize=(8, 8),autopct='%1.1f%%',\n        shadow=True, startangle=90,fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:53:16.556238Z","iopub.execute_input":"2022-06-12T12:53:16.556919Z","iopub.status.idle":"2022-06-12T12:53:16.733709Z","shell.execute_reply.started":"2022-06-12T12:53:16.556872Z","shell.execute_reply":"2022-06-12T12:53:16.732763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"เพื่อให้เห็นภาพบน Pie Chart ดังรูป","metadata":{}},{"cell_type":"markdown","source":" ค่า **Pearson Correlation **\n    \n    เป็นวิธีทางสถิติที่นิยมนำมาใช้วิเคราะห์เพื่อหาความสัมพันธ์ของข้อมูลมากที่สุดวิธีหนึ่ง เนื่องจากเป็นวิธีที่เข้าใจง่ายและสามารถคำนวนได้ไม่ยาก โดยค่า Pearson Correlation จะมีค่าอยู่ระหว่าง -1.0 ถึง +1.0 ซึ่งหากมีค่าใกล้ -1.0 นั้นหมายความว่าตัวแปรทั้งสองตัวมีความสัมพันธ์กันอย่างมากในเชิงตรงกันข้าม หากมีค่าใกล้ +1.0 นั้นหมายความว่า ตัวแปรทั้งสองมีความสัมพันธ์กันอย่างมากในทิศทางเดียวกัน และหากมีค่าเป็น 0 นั้นหมายความว่า ตัวแปรทั้งสองตัวไม่มีความสัมพันธ์ต่อกัน","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(figsize = (14,12))\nplt.title('Pearson Correlation of Features',loc = 'center',fontsize= 14)\nsns.heatmap(df_out.corr(),linewidths=0.1,vmax=1.0,vmin = -1.0,\n            square=True, linecolor='white', annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:57:32.463598Z","iopub.execute_input":"2022-06-12T10:57:32.464494Z","iopub.status.idle":"2022-06-12T10:57:34.669485Z","shell.execute_reply.started":"2022-06-12T10:57:32.464451Z","shell.execute_reply":"2022-06-12T10:57:34.668108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"จากภาพข้อมูล Pearson Correlation เพื่อแสดงความสัมพันธ์ของแต่ละ feature  ค่า x แต่ละค่ากับ y ","metadata":{}},{"cell_type":"code","source":"x_train = df_out.drop(columns='y')\ny_train = df_out['y']\nx_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:54:02.820581Z","iopub.execute_input":"2022-06-12T12:54:02.82146Z","iopub.status.idle":"2022-06-12T12:54:02.845932Z","shell.execute_reply.started":"2022-06-12T12:54:02.82141Z","shell.execute_reply":"2022-06-12T12:54:02.845045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_norm.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:54:05.250761Z","iopub.execute_input":"2022-06-12T12:54:05.251575Z","iopub.status.idle":"2022-06-12T12:54:05.273175Z","shell.execute_reply.started":"2022-06-12T12:54:05.25153Z","shell.execute_reply":"2022-06-12T12:54:05.272027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"การจัดการข้อมูลที่หายไปโดยใช้ธี Oversampling \n\nOversampling โดยใช้ SMOTE\n    SMOTE (Synthetic Minority Oversampling Technique) เราจะทำการรวบรวม Elements สำหรับ Minority Class ใน Vicinity ของ Element ที่มีอยู่แล้ว โดยมีวิธีการดังนี้ คือ\n     ซึ่งมีวิธีการคือ\n\n* ระบุ feature vector และ จุดที่ใกล้ที่สุด\n* ใช้ความแตกต่างระหว่างทั้งสอง\n* คูณความแตกต่างด้วยตัวเลขสุ่มระหว่าง 0 ถึง 1\n* ระบุจุดใหม่บนส่วนของเส้นตรงโดยการเพิ่มหมายเลขสุ่มลงใน feature vector\n* ทำซ้ำขั้นตอนสำหรับ feature vector ที่ระบุ\n\n\n![](http://images.techstarthailand.com/images/blog/Article2019/SamplingAlgorithms/SMOTE01.png)","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nx_sm, y_sm = smote.fit_resample(x_train, y_train)\n\nx_sm","metadata":{"execution":{"iopub.status.busy":"2022-06-12T12:54:15.901914Z","iopub.execute_input":"2022-06-12T12:54:15.90221Z","iopub.status.idle":"2022-06-12T12:54:16.174596Z","shell.execute_reply.started":"2022-06-12T12:54:15.902175Z","shell.execute_reply":"2022-06-12T12:54:16.173779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Feature Selection","metadata":{}},{"cell_type":"markdown","source":"feature selection คือ การเลือก feature ที่สำคัญ และเกี่ยวข้องมากที่สุดจากชุดคุณสมบัติมากมายในชุดข้อมูลที่กำหนดซึ่งช่วยมีผลในการการเทรนโมเดลดงนี้\n* เทรนโมเดลเร็วขึ้น\n* ลดความซับซ้อนของโมเดล สามารถตีความได้ง่ายมากขึ้น\n* ลดการ overfitting ที่อาจเกิดขึ้นได้\n\n\n    การทำ ANOVA เป็นวิธีการหนึ่ง เพื่อหาความจัดการ feature ซึ่งหน้าที่ของ ANOVA นั้น มีไว้เพื่อทดสอบสมมติฐานทางสถิติของตัวแปรที่มากกว่า 2 มีความสัมพันธ์กันอย่างไรแบบ Univariate feature selection โดยการเลือก feature โดย f-core ซึ่งเป็นวิธีการทางสถิติทดสอบ มันสามารถเห็นได้ว่าเป็นขั้นตอนก่อนการประมวลผลไปยังตัวประมาณ ในที่นี้โดยตั้ง นัยสำคัญของข้อมูลที่ 0.05 โดยทดสอบสมมุติฐาน x1,x2,x3,... x20 มีผลต่อ y ","metadata":{}},{"cell_type":"code","source":"BestFeatures = SelectKBest(score_func=f_classif, k=10)\nfit = BestFeatures.fit(x_train,y_train)\n\ndf_scores = pd.DataFrame(fit.scores_)\ndf_columns = pd.DataFrame(x_train.columns)\n\nf_Scores = pd.concat([df_columns,df_scores],axis=1)              \nf_Scores.columns = ['features','Score']  \n\nf_Scores","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:02:59.31251Z","iopub.execute_input":"2022-06-12T13:02:59.312881Z","iopub.status.idle":"2022-06-12T13:02:59.333721Z","shell.execute_reply.started":"2022-06-12T13:02:59.312845Z","shell.execute_reply":"2022-06-12T13:02:59.332821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_Scores[f_Scores['Score']<0.05]","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:48.780889Z","iopub.execute_input":"2022-06-12T10:38:48.78158Z","iopub.status.idle":"2022-06-12T10:38:48.791463Z","shell.execute_reply.started":"2022-06-12T10:38:48.781547Z","shell.execute_reply":"2022-06-12T10:38:48.790882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"แสดงให้เห็นว่า ค่า f-score ของ x1,x4,x20 มีค่าน้อยกว่า 0.05 ซึ่งจะทำการ feature นี้ออก เพื่อใช้ในการสร้าง train model ต่อไป\n","metadata":{}},{"cell_type":"code","source":"x_train.drop(columns = ['x1','x4','x20'])\ny_train.drop(columns = ['x1','x4','x20'])\ndf_test_norm.drop(columns = ['x1','x4','x20'])","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:06:10.980177Z","iopub.execute_input":"2022-06-12T13:06:10.981431Z","iopub.status.idle":"2022-06-12T13:06:11.011538Z","shell.execute_reply.started":"2022-06-12T13:06:10.981383Z","shell.execute_reply":"2022-06-12T13:06:11.010735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training and Evaluating Model ","metadata":{}},{"cell_type":"markdown","source":"Cross validate models \n\nโดยการเปรียบเทียบโมเดลที่ดังนี้โดยทำ cross validation โมเดลและดูผลเบื้องต้นเพื่อใช้ในการวิเคราะห์และเลือกโมเดลต่อไป\n\n* SVC\n* AdaBoost\n* Random Forest\n* Extra Trees\n* Gradient Boosting\n* KNN\n* Logistic regression\n","metadata":{}},{"cell_type":"code","source":"def model_cross_validation(x_train,y_train,random_state):\n    kfold = StratifiedKFold(n_splits = 5)\n    model_accuracy_result_cv = {\"LogisticRegression\":'',\n                           \"SVM\":'',\n                          \"Randomforest\":'',\n                          \"GradientBoosting\":'',\n                           \"AdaBoostiong\":'',\n                           \"ExtraTree\":''}\n    \n    #model classification\n    LG = LogisticRegression(random_state=random_state)\n    SVM = SVC(random_state=random_state)\n    RF = RandomForestClassifier(random_state=random_state)\n    KNN = KNeighborsClassifier()\n    GB = GradientBoostingClassifier(random_state=random_state)\n    AB = AdaBoostClassifier(random_state=random_state,learning_rate=0.1)\n    ET = ExtraTreesClassifier(random_state=random_state)\n    ml_model = [LG,SVM,RF,KNN,GB,AB,ET]\n    \n    cv_results = []\n    for ml in ml_model :\n        cv_results.append(cross_val_score(ml,X = x_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=5))\n    \n    cv_means = []\n    cv_std = []\n    for result in cv_results:\n        cv_means.append(result.mean())\n        cv_std.append(result.std())\n       \n\n    cv_res = pd.DataFrame({\"CV Means\":cv_means,\n                           \"CV errors\": cv_std,\n                           \"Algorithm\":[\"LogisticRegression\",\n                                       \"SVM\",\n                                       \"RadomForest\",\n                                        \"KNN\",\n                                       \"GradientBoosting\",\n                                       \"AdaBoosting\",\n                                       \"ExtraTree\"]})\n    print(cv_res)\n    g = sns.barplot(\"CV Means\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n    g.set_xlabel(\"CV Mean Accuracy\")\n    g = g.set_title(\"Cross Validation Evaluation\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:19:34.337028Z","iopub.execute_input":"2022-06-12T13:19:34.337349Z","iopub.status.idle":"2022-06-12T13:19:34.348517Z","shell.execute_reply.started":"2022-06-12T13:19:34.337309Z","shell.execute_reply":"2022-06-12T13:19:34.347927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cross_validation(x_train = x_sm,y_train = y_sm,random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:19:39.446968Z","iopub.execute_input":"2022-06-12T13:19:39.447268Z","iopub.status.idle":"2022-06-12T13:19:59.987123Z","shell.execute_reply.started":"2022-06-12T13:19:39.447236Z","shell.execute_reply":"2022-06-12T13:19:59.98606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"จากข้อูลการทำ Cross Validation พบว่า ค่าไม่แตกต่างกันมาก เกือบทุก model ทีค่า accuracy mean ไม่แตกต่างกันมากทำให้ยากที่จะประเมิน แต่จากข้อมูลเบิ้องต้นแต่ละโมเดลค่อยข้างมีค่า accuracy สูงอยู่ที่ประมาณ 0.95 เกือบทั้งหมด ่ต่อไปจะเป็นการ Hyperparameter Tuning เพื่อ Optimization model ให้ดีมากขึ้นพัฒนา Performance ของแต่ละ model แต่จากผล จะทำการ Tuning Model \n\n","metadata":{}},{"cell_type":"markdown","source":"# 5.HyperParameter Tuning","metadata":{}},{"cell_type":"markdown","source":"การทำ Hyperparameter Tuning ในบางครั้งอาจจะถูกเรียกว่า Hyperparameter Optimization นับได้ว่าเป็น Optimization Problem รูปแบบหนึ่ง เนื่องจากเราต้องการหาว่า Set ของ Hyperparameters ที่เหมาะสมสำหรับโมเดลประเภทนั้น ๆ ที่จะส่งผลให้โมเดลมีความแม่นยำ (Accuracy) ที่สูง หรือต้องการลดค่า Loss ให้มีค่าต่ำที่สุด โดยทำการ Tuning ทุกโมเดล และ แสดงค่า accuracy ที่ดีที่สุดของแต่ละโมเดล เพื่อทำการเลือกโมเดลที่เหมาะสมที่สุด","metadata":{}},{"cell_type":"code","source":"# Cross validate model with Kfold\nkfold = StratifiedKFold(n_splits = 5)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:21:56.566902Z","iopub.execute_input":"2022-06-12T13:21:56.568211Z","iopub.status.idle":"2022-06-12T13:21:56.572306Z","shell.execute_reply.started":"2022-06-12T13:21:56.56816Z","shell.execute_reply":"2022-06-12T13:21:56.57151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AdaBoost \nDTC = DecisionTreeClassifier()\n\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\n\n#Search grid for optimal parameters\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[1,2],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsadaDTC.fit(x_sm,y_sm)\n\nada_best = gsadaDTC.best_estimator_\n\n# Best score\ngsadaDTC.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.932489Z","iopub.status.idle":"2022-06-12T10:38:50.933098Z","shell.execute_reply.started":"2022-06-12T10:38:50.932923Z","shell.execute_reply":"2022-06-12T10:38:50.932943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ExtraTrees \nExtC = ExtraTreesClassifier()\n\n#Search grid for optimal parameters\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3,10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsExtC.fit(x_train,y_train)\n\nExtC_best = gsExtC.best_estimator_\n\n# Best score\ngsExtC.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.934021Z","iopub.status.idle":"2022-06-12T10:38:50.934549Z","shell.execute_reply.started":"2022-06-12T10:38:50.934365Z","shell.execute_reply":"2022-06-12T10:38:50.934385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Support Vetor Machine\nSVMC = SVC(probability=True)\n\n#Search grid for optimal parameters\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\n\n\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsSVMC.fit(x_sm,y_sm)\n\nSVMC_best = gsSVMC.best_estimator_\n\n# Best score\ngsSVMC.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.93579Z","iopub.status.idle":"2022-06-12T10:38:50.936092Z","shell.execute_reply.started":"2022-06-12T10:38:50.935939Z","shell.execute_reply":"2022-06-12T10:38:50.935955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForest\nRFC = RandomForestClassifier()\n\n#Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsRFC.fit(x_sm,y_sm)\n\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.937084Z","iopub.status.idle":"2022-06-12T10:38:50.937383Z","shell.execute_reply.started":"2022-06-12T10:38:50.937225Z","shell.execute_reply":"2022-06-12T10:38:50.937241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNeighborsNearest\nKNN = KNeighborsClassifier()\n\n#Search grid for optimal parameters\nKNN_params_grid = {'n_neighbors':[6,8,10,12,14,16,18,20],\n         'leaf_size':list(range(1,50,5))}\n\ngsKNN = GridSearchCV(KNN, param_grid= KNN_params_grid, cv = kfold,scoring = \"accuracy\",verbose=1)\n\ngsKNN.fit(x_sm,y_sm)\n\nKNN_best = gsKNN.best_estimator_\n\n# Best score\ngsKNN.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.939054Z","iopub.status.idle":"2022-06-12T10:38:50.939575Z","shell.execute_reply.started":"2022-06-12T10:38:50.939406Z","shell.execute_reply":"2022-06-12T10:38:50.939425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\nlrr = LogisticRegression()\n\n#Search grid for optimal parameters\nlrr_params_grid ={\"C\":np.logspace(-3,3,7), \n      \"penalty\":[\"l1\",\"l2\"]}\n\ngsLRR =GridSearchCV(lrr,param_grid=lrr_params_grid,cv=kfold)\n\ngsLRR.fit(x_sm,y_sm)\n\nLRR_best = gsLRR.best_estimator_\n\n# Best score\ngsLRR.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.940442Z","iopub.status.idle":"2022-06-12T10:38:50.940732Z","shell.execute_reply.started":"2022-06-12T10:38:50.940573Z","shell.execute_reply":"2022-06-12T10:38:50.940588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gradientboosting\n\nGBC = GradientBoostingClassifier()\n\n#Search grid for optimal parameters\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(x_sm,y_sm)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.941589Z","iopub.status.idle":"2022-06-12T10:38:50.941912Z","shell.execute_reply.started":"2022-06-12T10:38:50.941721Z","shell.execute_reply":"2022-06-12T10:38:50.941744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.Learning Curve ","metadata":{}},{"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.94305Z","iopub.status.idle":"2022-06-12T10:38:50.943343Z","shell.execute_reply.started":"2022-06-12T10:38:50.94319Z","shell.execute_reply":"2022-06-12T10:38:50.943206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = plot_learning_curve(gsExtC.best_estimator_,\"ExtraTrees learning curves\",x_train,y_train,cv=kfold)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = plot_learning_curve(gsSVMC.best_estimator_,\"SVC learning curves\",x_train,y_train,cv=kfold)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = plot_learning_curve(gsadaDTC.best_estimator_,\"AdaBoost learning curves\",x_train,y_train,cv=kfold)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = plot_learning_curve(gsRFC.best_estimator_,\"RF mearning curves\",x_train,y_train,cv=kfold)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = plot_learning_curve(gsKNN.best_estimator_,\"KNN mearning curves\",x_train,y_train,cv=kfold)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.944313Z","iopub.status.idle":"2022-06-12T10:38:50.944614Z","shell.execute_reply.started":"2022-06-12T10:38:50.94446Z","shell.execute_reply":"2022-06-12T10:38:50.944475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = plot_learning_curve(gsLRR.best_estimator_,\"LRR mearning curves\",x_train,y_train,cv=kfold)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.945444Z","iopub.status.idle":"2022-06-12T10:38:50.945733Z","shell.execute_reply.started":"2022-06-12T10:38:50.945574Z","shell.execute_reply":"2022-06-12T10:38:50.945589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = plot_learning_curve(gsGBC.best_estimator_,\"GBC mearning curves\",x_train,y_train,cv=kfold)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.946816Z","iopub.status.idle":"2022-06-12T10:38:50.947137Z","shell.execute_reply.started":"2022-06-12T10:38:50.946982Z","shell.execute_reply":"2022-06-12T10:38:50.946999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GradientBoosting,RandomForest,SupportVectorMachine และ Adaboost มีแนวโน้มที่จะเกิด Overfitting แต่ cross validation ยังคงมีค่า accuracy สูงกว่า model อื่นดังรูปที่ CV line อยู่ต่ำกว่า training line ซึ่งหากมี training dataset ที่เพิ่มขึ่นอาจจะทำให้ถึงจุดที่ optimal ของ model ดังกราฟ \n\nKNN และ Logistic จะสรุปค่อยข้าง good fit กว่าโมเดลอื่น เพราะ เส้นทั้ง 2 วิ่งใกล้กันและเข้าหากัน","metadata":{}},{"cell_type":"code","source":"corr = pd.concat([pd.Series(RFC_best.predict(df_test_norm), name=\"RF\"),\n                              pd.Series(ExtC_best.predict(df_test_norm), name=\"EXT\"),\n                              pd.Series(SVMC_best.predict(df_test_norm), name=\"SVC\"),\n                              pd.Series(KNN_best.predict(df_test_norm), name=\"KNN\"),\n                              pd.Series(LRR_best.predict(df_test_norm), name=\"LRR\"),\n                              pd.Series(ada_best.predict(df_test_norm), name=\"ADA\"),\n                              pd.Series(GBC_best.predict(df_test_norm), name=\"GBC\")],axis=1)\n\nplt.figure(figsize=(18,18))\nsns.heatmap(corr.corr(),annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.948161Z","iopub.status.idle":"2022-06-12T10:38:50.948484Z","shell.execute_reply.started":"2022-06-12T10:38:50.94831Z","shell.execute_reply":"2022-06-12T10:38:50.948333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"แต่ละ model เหมือนจะค่อนข้างคล้ายกันไม่แตกต่างกันมากจาก ข้อมูล pearson correlation ระหว่างโมเดลแต่ละตัว โดยเลือกโมเดล 4 ตัวที่ดีที่สุด มาทำการ ensemble model โดย ใช้ VotingClassification แบบ Soft โดยแต่ละ model จะทำนายป้ายกำกับคลาสตาม argmax ของผลรวมของความน่าจะเป็นที่คาดการณ์ไว้ โดยโมเดลที่ใช้โหวต คือ\n\n1. ExtraTreeClassification\n2. SupportVectorMachine\n3. RandomForest\n4. GradientBoosting","metadata":{}},{"cell_type":"code","source":"#VotingClassification\nvotingC = VotingClassifier(estimators= [('extc',ExtC_best),\n('svc', SVMC_best),('rfc',RFC_best),('gbc',GBC_best)],voting = 'soft')\n\nvotingC.fit(x_train, y_train)\n\nvotingC.predict(df_test_norm)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.949677Z","iopub.status.idle":"2022-06-12T10:38:50.9514Z","shell.execute_reply.started":"2022-06-12T10:38:50.951209Z","shell.execute_reply":"2022-06-12T10:38:50.951238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['id','Expected']\npredict_result = votingC.predict(df_test_norm)\npredict_result = predict_result.astype(int)\ndf_predict = pd.DataFrame({\n    \"id\":list(range(1,2501)),\n    \"Expected\":predict_result\n})\n\ndf_predict['Expected'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.952256Z","iopub.status.idle":"2022-06-12T10:38:50.952663Z","shell.execute_reply.started":"2022-06-12T10:38:50.952506Z","shell.execute_reply":"2022-06-12T10:38:50.952524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:38:50.953748Z","iopub.status.idle":"2022-06-12T10:38:50.954342Z","shell.execute_reply.started":"2022-06-12T10:38:50.954167Z","shell.execute_reply":"2022-06-12T10:38:50.954185Z"},"trusted":true},"execution_count":null,"outputs":[]}]}